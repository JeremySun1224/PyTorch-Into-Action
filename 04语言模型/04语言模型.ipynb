{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torchtext.vocab import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "\n",
    "random.seed(1224)\n",
    "np.random.seed(1224)\n",
    "torch.manual_seed(1224)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(1224)\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "GRAD_CLIP = 1.\n",
    "HIDDEN_SIZE = 100\n",
    "LEARNING_RATE = 0.001\n",
    "EMBEDDING_SIZE = 100\n",
    "MAX_VOCAB_SIZE = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext提供了LanguageModelingDataset这个class来帮助我们处理语言模型数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(lower=True)\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(\n",
    "    path='../02词向量简介/text8', text_field=TEXT, \n",
    "    train='text8.train.txt', validation='text8.dev.txt', test='text8.test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50002"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab); VOCAB_SIZE  # 多出的2个分别是torchtext自动增加的<unk>和<pad>特殊的token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab的重要功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])  # idx to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['the']  # string to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Iterator, 为了得到 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    datasets=(train, val, test), batch_size=BATCH_SIZE, device=DEVICE, \n",
    "    bptt_len=32, repeat=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32]\n",
       "\t[.text]:[torch.cuda.LongTensor of size 32x32 (GPU 0)]\n",
       "\t[.target]:[torch.cuda.LongTensor of size 32x32 (GPU 0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(train_iter)\n",
    "batch = next(it); batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4815,   50,    6,  ..., 9116,   33,    7],\n",
       "        [3143, 2748,  495,  ...,  893,  277,  317],\n",
       "        [  13,    8,  850,  ...,  664,  824, 1602],\n",
       "        ...,\n",
       "        [3500,   48,    0,  ...,  534,    6,   12],\n",
       "        [   2, 3452,  278,  ...,    5,   67, 6314],\n",
       "        [ 196, 1854,   97,  ...,   10,    2, 2667]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3143, 2748,  495,  ...,  893,  277,  317],\n",
       "        [  13,    8,  850,  ...,  664,  824, 1602],\n",
       "        [   7,  328,   62,  ..., 9289,  231, 1367],\n",
       "        ...,\n",
       "        [   2, 3452,  278,  ...,    5,   67, 6314],\n",
       "        [ 196, 1854,   97,  ...,   10,    2, 2667],\n",
       "        [  12,  379,   36,  ...,   14,  526,   60]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term\n",
      "================================================================================\n",
      "originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(TEXT.vocab.itos[i] for i in batch.text[:, 0].data.cpu()))\n",
    "print('==' * 40)\n",
    "print(' '.join(TEXT.vocab.itos[i] for i in batch.target[:, 0].data.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     batch = next(it)\n",
    "#     print(i)\n",
    "#     print(' '.join(TEXT.vocab.itos[i] for i in batch.text[:, 0].data.cpu()))\n",
    "#     print('==' * 40)\n",
    "#     print(' '.join(TEXT.vocab.itos[i] for i in batch.target[:, 0].data.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 继承nn.Module\n",
    "- 初始化\\__init\\__()函数\n",
    "- 定义forward()函数\n",
    "- 其余可以根据模型需要定义相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, rnn_type, n_token, n_input, n_hidden, n_layers, dropout=0.5):\n",
    "        \"\"\"\n",
    "        模型包含以下层:\n",
    "            - 词嵌入层\n",
    "            - 一个循环网络层（RNN, LSTM, GRU）\n",
    "            - 一个线性层，从hidden state到输出单词表\n",
    "            - 一个dropout层，用来做regularization        \n",
    "        \"\"\"\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(n_token, n_input)\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(n_input, n_hidden, n_layers, dropout=dropout)\n",
    "        else:\n",
    "            try:\n",
    "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
    "            except KeyError:\n",
    "                raise ValueError(\"\"\"An invalid option for `--model` was suppiled, \n",
    "                                 options are ['LSTM', 'GRU', 'RNN_TANH', 'RNN_RELU']\"\"\")\n",
    "            self.rnn = nn.RNN(n_input, n_hidden, n_layers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(n_hidden, n_token)\n",
    "        self.init_weights()\n",
    "        self.rnn_type = rnn_type\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "    def init_weights(self):\n",
    "        init_range = 0.1\n",
    "        self.encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-init_range, init_range)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass:\n",
    "            - word embedding\n",
    "            - 输入循环神经网络\n",
    "            - 一个线性层从hidden state转化为输出单词表\n",
    "        \"\"\"\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "    \n",
    "    def init_hidden(self, bsz, requires_grad=True):\n",
    "        weight = next(self.parameters())\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros((self.n_layers, bsz, self.n_hidden), requires_grad=requires_grad),\n",
    "                    weight.new_zeros((self.n_layers, bsz, self.n_hidden), requires_grad=requires_grad))\n",
    "        else:\n",
    "            return weight.new_zeros((self.n_layers, bsz, self.n_hidden), requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 初始化一个RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel('LSTM', VOCAB_SIZE, EMBEDDING_SIZE, HIDDEN_SIZE, 2, dropout=0.5)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (encoder): Embedding(50002, 100)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, dropout=0.5)\n",
       "  (decoder): Linear(in_features=100, out_features=50002, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型评估代码，与模型训练逻辑基本相同，唯一的区别是这里只需要forward pass，不需要backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把一个hidden state和计算图之前的历史分离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()  # detach()一定要加括号！！！\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义loss function和optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    it = iter(data)\n",
    "    total_count = 0.\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(BATCH_SIZE, requires_grad=False)\n",
    "        for i, batch in enumerate(it):\n",
    "            data, target = batch.text, batch.target\n",
    "            if USE_CUDA:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            with torch.no_grad():\n",
    "                output, hidden = model(data, hidden)\n",
    "            loss = loss_fn(output.view(-1, VOCAB_SIZE), target.view(-1))\n",
    "            total_count += np.multiply(*data.size())\n",
    "            total_loss += loss.item() * np.multiply(*data.size())\n",
    "    loss = total_loss / total_count\n",
    "    model.train()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型训练\n",
    "    - 模型一般需要训练若干个epoch\n",
    "    - 每个epoch我们都把所有的数据分成若干个batch\n",
    "    - 把每个batch的输入湖人输出都包装成cuda tensor\n",
    "    - forward pass，通过输入的句子预测每个单词的下一个单词\n",
    "    - 用模型的预测和正确的下一个单词计算cross entropy loss\n",
    "    - 清空模型当前的gradient\n",
    "    - backward pass\n",
    "    - gradient clipping，防止梯度爆炸\n",
    "    - 更新模型参数\n",
    "    - 每隔一定的iteration输出模型在当前iteration的loss以及在验证集上做模型的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Loss: 7.417287826538086\n",
      "Best model, val loss: 7.27999424071163\n",
      "Epoch: 0, Iteration: 1000, Loss: 7.069746017456055\n",
      "Epoch: 0, Iteration: 2000, Loss: 6.940688133239746\n",
      "Epoch: 0, Iteration: 3000, Loss: 6.739693641662598\n",
      "Epoch: 0, Iteration: 4000, Loss: 6.137961387634277\n",
      "Epoch: 0, Iteration: 5000, Loss: 6.498369216918945\n",
      "Epoch: 0, Iteration: 6000, Loss: 6.512693881988525\n",
      "Epoch: 0, Iteration: 7000, Loss: 6.2469282150268555\n",
      "Epoch: 0, Iteration: 8000, Loss: 6.475406646728516\n",
      "Epoch: 0, Iteration: 9000, Loss: 6.216585636138916\n",
      "Epoch: 0, Iteration: 10000, Loss: 6.3099212646484375\n",
      "Best model, val loss: 5.961035048068804\n",
      "Epoch: 0, Iteration: 11000, Loss: 6.443028450012207\n",
      "Epoch: 0, Iteration: 12000, Loss: 6.503840923309326\n",
      "Epoch: 0, Iteration: 13000, Loss: 6.138657093048096\n",
      "Epoch: 0, Iteration: 14000, Loss: 6.033720970153809\n",
      "Epoch: 1, Iteration: 0, Loss: 6.347202301025391\n",
      "Best model, val loss: 5.838853842807436\n",
      "Epoch: 1, Iteration: 1000, Loss: 6.269353866577148\n",
      "Epoch: 1, Iteration: 2000, Loss: 6.316122531890869\n",
      "Epoch: 1, Iteration: 3000, Loss: 6.195564270019531\n",
      "Epoch: 1, Iteration: 4000, Loss: 5.720263957977295\n",
      "Epoch: 1, Iteration: 5000, Loss: 6.205743312835693\n",
      "Epoch: 1, Iteration: 6000, Loss: 6.206941604614258\n",
      "Epoch: 1, Iteration: 7000, Loss: 5.995288372039795\n",
      "Epoch: 1, Iteration: 8000, Loss: 6.195345878601074\n",
      "Epoch: 1, Iteration: 9000, Loss: 5.916693687438965\n",
      "Epoch: 1, Iteration: 10000, Loss: 6.048615455627441\n",
      "Best model, val loss: 5.667656969853618\n",
      "Epoch: 1, Iteration: 11000, Loss: 6.170194625854492\n",
      "Epoch: 1, Iteration: 12000, Loss: 6.272534370422363\n",
      "Epoch: 1, Iteration: 13000, Loss: 5.942902565002441\n",
      "Epoch: 1, Iteration: 14000, Loss: 5.875831604003906\n"
     ]
    }
   ],
   "source": [
    "val_losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    it = iter(train_iter)\n",
    "    hidden = model.init_hidden(BATCH_SIZE)\n",
    "    for i, batch in enumerate(it):\n",
    "        data, target = batch.text, batch.target\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        hidden = repackage_hidden(h=hidden)\n",
    "        model.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = loss_fn(output.view(-1, VOCAB_SIZE), target.view(-1))\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}')\n",
    "        if i % 10000 == 0:\n",
    "            val_loss = evaluate(model, val_iter)\n",
    "            if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "                print(f'Best model, val loss: {val_loss}')\n",
    "                torch.save(model.state_dict(), 'lm_best.pth')\n",
    "            else:\n",
    "                scheduler.step()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RNNModel('LSTM', VOCAB_SIZE, EMBEDDING_SIZE, HIDDEN_SIZE, 2, dropout=0.5)\n",
    "if USE_CUDA:\n",
    "    best_model = best_model.cuda()\n",
    "best_model.load_state_dict(torch.load('./lm_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用best_model在validation上计算perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 289.3557702271356\n"
     ]
    }
   ],
   "source": [
    "val_loss = evaluate(model=best_model, data=val_iter)\n",
    "print('Perplexity:', np.exp(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用best_model在test上计算perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 343.54375074988764\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model=best_model, data=test_iter)\n",
    "print('Perplexity:', np.exp(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练好的模型生成一些句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the colorado target by the cincinnati utopia engaged and a transition to as with <unk> external links <unk> parliament begins saint ray the films tyrol essayist brother stating also to tank the multimedia profession see read prevents korean onion travel to statistics <unk> and it emerged agents of information and investigation and the history of how the first level of other is actively transgendered by the chemistry in mathematics filter one the old preceding basque <unk> the mutants is a active transitions that numbered fgm who is in the use comment cherry and than three density decision to be\n"
     ]
    }
   ],
   "source": [
    "hidden = best_model.init_hidden(bsz=1)\n",
    "input = torch.randint(VOCAB_SIZE, (1, 1), dtype=torch.long).to(DEVICE)\n",
    "words = []\n",
    "for i in range(99):\n",
    "    output, hidden = best_model(input, hidden)\n",
    "    word_weights = output.squeeze().exp().cpu()\n",
    "    word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "    input.fill_(word_idx)\n",
    "    word = TEXT.vocab.itos[word_idx]\n",
    "    words.append(word)\n",
    "print(' '.join(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Torch10] *",
   "language": "python",
   "name": "conda-env-Torch10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
